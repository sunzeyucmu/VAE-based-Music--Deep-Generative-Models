{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DilatedConv_VQ-VAE_PIXELCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Local Runtime\n",
        "jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0"
      ],
      "metadata": {
        "id": "VzTdibB699ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow_addons import layers as addon_layers"
      ],
      "metadata": {
        "id": "EwlE2kDX-cZI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)\n",
        "# print(addon_layers.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZc4puJf-lJT",
        "outputId": "046e4448-d73f-4c98-ef6f-0008bab061b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataSet"
      ],
      "metadata": {
        "id": "eLS1rQEV9_pZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A9Aa-9S592Si"
      },
      "outputs": [],
      "source": [
        "## Local Data-path\n",
        "DATA_PATH = \"GENERATIVE_DATA/LJSpeech-1.1/wavs/*.wav\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in 13100 discrete speech samples (wav files and ignore the audio annotations)\n",
        "wavs = tf.io.gfile.glob(DATA_PATH)\n",
        "print(f\"Number of audio files: {len(wavs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pODsC66O-w49",
        "outputId": "efbdea3c-374c-469d-f6f0-ad3c15011c47"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of audio files: 13100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BYFXU3qD-2ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Structure"
      ],
      "metadata": {
        "id": "I3iR7kfBONy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dialated Residual Block"
      ],
      "metadata": {
        "id": "mZc2RYS8OPzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_stack(input, filters):\n",
        "    \"\"\"Convolutional residual stack with weight normalization.\n",
        "\n",
        "       Dilated Conv: A dilated convolution effectively allows the network to operate on \n",
        "                     a coarser scale than with a normal convolution. This is similar to pooling or strided convolutions, but\n",
        "                     here the $$output has the same size as the input$$.\n",
        "    Args:\n",
        "        filter: int, determines filter size for the residual stack.\n",
        "\n",
        "    Returns:\n",
        "        Residual stack output.\n",
        "    \"\"\"\n",
        "    c1 = addon_layers.WeightNormalization(\n",
        "        layers.Conv1D(filters, 3, dilation_rate=1, padding=\"same\"), data_init=False\n",
        "    )(input)\n",
        "    lrelu1 = layers.LeakyReLU()(c1)\n",
        "    c2 = addon_layers.WeightNormalization(\n",
        "        layers.Conv1D(filters, 3, dilation_rate=1, padding=\"same\"), data_init=False\n",
        "    )(lrelu1)\n",
        "    add1 = layers.Add()([c2, input])\n",
        "\n",
        "    lrelu2 = layers.LeakyReLU()(add1)\n",
        "    c3 = addon_layers.WeightNormalization(\n",
        "        layers.Conv1D(filters, 3, dilation_rate=3, padding=\"same\"), data_init=False\n",
        "    )(lrelu2)\n",
        "    lrelu3 = layers.LeakyReLU()(c3)\n",
        "    c4 = addon_layers.WeightNormalization(\n",
        "        layers.Conv1D(filters, 3, dilation_rate=1, padding=\"same\"), data_init=False\n",
        "    )(lrelu3)\n",
        "    add2 = layers.Add()([add1, c4])\n",
        "\n",
        "    lrelu4 = layers.LeakyReLU()(add2)\n",
        "    c5 = addon_layers.WeightNormalization(\n",
        "        layers.Conv1D(filters, 3, dilation_rate=9, padding=\"same\"), data_init=False\n",
        "    )(lrelu4)\n",
        "    lrelu5 = layers.LeakyReLU()(c5)\n",
        "    c6 = addon_layers.WeightNormalization(\n",
        "        layers.Conv1D(filters, 3, dilation_rate=1, padding=\"same\"), data_init=False\n",
        "    )(lrelu5)\n",
        "    add3 = layers.Add()([c6, add2])\n",
        "\n",
        "    return add3"
      ],
      "metadata": {
        "id": "5H7aAb3iOPLp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_in_shape = (128, 4) # (T, C)\n",
        "test_fiters = 4 # out_channel size, needs to be same as input filters size for residual connection\n",
        "test_in = keras.Input(test_in_shape)\n",
        "test_out = residual_stack(test_in, test_fiters)\n",
        "test_model = keras.Model(test_in, test_out)\n",
        "\n",
        "test_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NlNn88KOUYJ",
        "outputId": "f54575a7-de39-4e51-912f-9fd2b12d83bb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 128, 4)]     0           []                               \n",
            "                                                                                                  \n",
            " weight_normalization_24 (Weigh  (None, 128, 4)      57          ['input_5[0][0]']                \n",
            " tNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " leaky_re_lu_18 (LeakyReLU)     (None, 128, 4)       0           ['weight_normalization_24[0][0]']\n",
            "                                                                                                  \n",
            " weight_normalization_25 (Weigh  (None, 128, 4)      57          ['leaky_re_lu_18[0][0]']         \n",
            " tNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 128, 4)       0           ['weight_normalization_25[0][0]',\n",
            "                                                                  'input_5[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_19 (LeakyReLU)     (None, 128, 4)       0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " weight_normalization_26 (Weigh  (None, 128, 4)      57          ['leaky_re_lu_19[0][0]']         \n",
            " tNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " leaky_re_lu_20 (LeakyReLU)     (None, 128, 4)       0           ['weight_normalization_26[0][0]']\n",
            "                                                                                                  \n",
            " weight_normalization_27 (Weigh  (None, 128, 4)      57          ['leaky_re_lu_20[0][0]']         \n",
            " tNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 128, 4)       0           ['add_12[0][0]',                 \n",
            "                                                                  'weight_normalization_27[0][0]']\n",
            "                                                                                                  \n",
            " leaky_re_lu_21 (LeakyReLU)     (None, 128, 4)       0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " weight_normalization_28 (Weigh  (None, 128, 4)      57          ['leaky_re_lu_21[0][0]']         \n",
            " tNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " leaky_re_lu_22 (LeakyReLU)     (None, 128, 4)       0           ['weight_normalization_28[0][0]']\n",
            "                                                                                                  \n",
            " weight_normalization_29 (Weigh  (None, 128, 4)      57          ['leaky_re_lu_22[0][0]']         \n",
            " tNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 128, 4)       0           ['weight_normalization_29[0][0]',\n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 342\n",
            "Trainable params: 336\n",
            "Non-trainable params: 6\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample = tf.random.normal([32, 128, 4])\n",
        "test_res_out = residual_stack(test_sample, test_fiters)\n",
        "test_res_out.shape # dilation conv won't change input shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-tI3zrAPtkY",
        "outputId": "79a9d948-a79a-4f80-fdc2-b8a738e8b5d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 128, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PJ4Kc962RJFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mDRowY0ZQsPn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}